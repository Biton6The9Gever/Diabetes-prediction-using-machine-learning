# -*- coding: utf-8 -*-
"""AiProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16h77ld3604jNrZMbbJg88N7YRFh4jEX2
"""

!cp /content/drive/MyDrive/training_history.zip /content/
!unzip -o /content/drive/MyDrive/training_history.zip                                     # Load training history
!cp /content/drive/MyDrive/TabNet_model.zip /content/                                     # Load TabNet Model
!cp /content/drive/MyDrive/random_forest_model.sav /content/                             # Load RandomForest Model
!cp /content/drive/MyDrive/diabetes_binary_health_indicators_BRFSS2015.csv.zip /content/  # Load Data


!unzip -o /content/diabetes_binary_health_indicators_BRFSS2015.csv.zip                    # Unzip Data

!pip install pandas numpy tensorflow scikit-learn imbalanced-learn pytorch-tabnet matplotlib seaborn pickle-mixin joblib gradio

import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score
from imblearn.over_sampling import SMOTE
from pytorch_tabnet.tab_model import TabNetClassifier
from tensorflow.keras.models import Sequential, model_from_json, clone_model
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import SGD, Adam, RMSprop
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.regularizers import l2
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
import joblib
import gradio as gr
# Load the dataset
# https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset?resource=download
df = pd.read_csv("/content/diabetes_binary_health_indicators_BRFSS2015.csv")

global modelf , best_model, tabnet_clf ,history,all_history_data,feature_columns,X_train, X_test, y_train, y_test ,scaler

print(df.columns)
df.rename(columns={'Diabetes_binary': 'Output'}, inplace=True)
print(df.columns)

print(f"Duplicates are {df.duplicated().sum()}")
print("Droping all duplicates")
df.drop_duplicates(inplace = True)
print(f"Duplicates are {df.duplicated().sum()}")

# Check the columns and missing values for each column
max_len = max(df.columns.str.len())  # Get the longest column name for alignment

for col in df.columns:
    # Check if column is numeric
    if pd.api.types.is_numeric_dtype(df[col]):
        # Count the number of missing values
        missing_values = df[col].isna().sum()
        if missing_values > 0:
            print(f"{col: <{max_len}} | has {missing_values} missing values.")
        else:
            print(f"{col: <{max_len}} | has no missing values.")

output_percentage = df['Output'].value_counts(normalize=True) * 100

# Plot
plt.figure(figsize=(6, 4))
sns.barplot(x=output_percentage.index, y=output_percentage.values, palette='viridis')

plt.title('Class Distribution (%)')
plt.xlabel('Output Class')
plt.ylabel('Percentage')
plt.ylim(0, 100)

# Show percentage on bars
for i, v in enumerate(output_percentage.values):
    plt.text(i, v + 1, f"{v:.2f}%", ha='center', fontweight='bold')

plt.tight_layout()
plt.show()

feature_columns = [
    'HighBP', 'HighChol', 'BMI', 'Smoker', 'Stroke',
    'HeartDiseaseorAttack', 'PhysActivity',
    'NoDocbcCost', 'GenHlth',
    'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age'
]

scaler = MinMaxScaler()

# Apply the scaler
df[feature_columns] = scaler.fit_transform(df[feature_columns])

# X (features) are all columns
X = df[feature_columns]

# y (target) is the Output column
y = df['Output']

# Split the data into training and testing sets (60% train, 40% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)

# Check the shapes of X_train and y_train
print(f"X_train shape: {X_train.shape}")
print(f"y_train shape: {y_train.shape}")

# Define the improved predict function
def predict(modelf, inputs, targets, name=''):
    preds = modelf.predict(inputs)
    accuracy = accuracy_score(targets, preds)
    print(f"{name} Accuracy: {accuracy * 100:.2f}%")
    return preds, accuracy

# Train the Random Forest model
modelf = RandomForestClassifier(n_jobs=-1, random_state=42, class_weight='balanced')
modelf.fit(X_train, y_train)

# Evaluate on training and validation sets
train_preds, train_accuracy = predict(modelf, X_train, y_train, 'Train')
val_preds, val_accuracy = predict(modelf, X_test, y_test, 'Validation')
joblib.dump(modelf, 'random_forest_model.sav')

# Plot the confusion matrix only for Validation
cm_val = confusion_matrix(y_test, val_preds)

# Display confusion matrix for Validation (3 classes)
plt.figure(figsize=(7, 5))
sns.heatmap(cm_val, annot=True, fmt="d", cmap='Blues', xticklabels=['0', '1'], yticklabels=['0', '1'])
plt.title("Confusion Matrix - Validation")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

# Load training history
with open("training_history.pkl", "rb") as f:
    all_history_data = pickle.load(f)

# Find the best model index based on AUC
val_aucs = all_history_data["val_aucs"]
best_index = int(np.argmax(val_aucs))
best_auc = val_aucs[best_index]
print(f"Best model index: {best_index}, AUC: {best_auc:.4f}")

# Reconstruct the best model
best_model_json = all_history_data["models"][best_index]
best_model_weights = all_history_data["weights"][best_index]

best_model = model_from_json(best_model_json)
best_model.set_weights(best_model_weights)

# You need to compile it again to use `evaluate`, `predict`, etc.
from tensorflow.keras.optimizers import Adam
best_model.compile(optimizer=Adam(),  # or reuse from params if you want
              loss='binary_crossentropy',
              metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])

# Evaluate on test set (if you have X_test, y_test still)
# model.evaluate(X_test, y_test)

# Predict:
# predictions = model.predict(X_test)

# Print best model's parameters if needed
print("Best model hyperparameters:")
print(all_history_data["params"][best_index])

# Load the saved history file
with open('training_history.pkl', 'rb') as f:
    all_history_data = pickle.load(f)

num_runs = len(all_history_data.get("histories", []))

if num_runs == 0:
    print("No runs found in history.")
else:
    for run in range(num_runs):
        try:
            history = all_history_data["histories"][run]["history"]
            conf_matrix = all_history_data["confusion_matrices"][run]
            params = all_history_data["params"][run]

            train_acc = np.asarray(history.get("accuracy", []))
            val_acc = np.asarray(history.get("val_accuracy", []))
            train_loss = np.asarray(history.get("loss", []))
            val_loss = np.asarray(history.get("val_loss", []))

            if train_acc.size == 0 or val_acc.size == 0 or train_loss.size == 0 or val_loss.size == 0:
                print(f"Skipping Run {run+1} due to missing data.")
                continue

            print(f"\n====== Run {run+1} ======")
            print("Parameters:", params)

            plt.figure(figsize=(15, 5))

            # Accuracy plot
            plt.subplot(1, 3, 1)
            plt.plot(train_acc, label='Train Accuracy')
            plt.plot(val_acc, '--', label='Validation Accuracy')
            plt.title(f'Run {run+1} Accuracy')
            plt.xlabel('Epoch')
            plt.ylabel('Accuracy')
            plt.legend()

            # Loss plot
            plt.subplot(1, 3, 2)
            plt.plot(train_loss, label='Train Loss')
            plt.plot(val_loss, '--', label='Validation Loss')
            plt.title(f'Run {run+1} Loss')
            plt.xlabel('Epoch')
            plt.ylabel('Loss')
            plt.legend()

            # Confusion matrix heatmap
            plt.subplot(1, 3, 3)
            sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
            plt.title(f'Run {run+1} Confusion Matrix')
            plt.xlabel('Predicted')
            plt.ylabel('True')

            plt.tight_layout()
            plt.show()

        except Exception as e:
            print(f"Error plotting Run {run+1}: {e}")

def submit_form(HighBP, HighChol, BMI, Smoker, Stroke, HeartDiseaseorAttack,
                PhysActivity, NoDocbcCost, GenHlth, MentHlth, PhysHlth,
                DiffWalk, Sex, Age):

    features = {
        'HighBP': 1 if HighBP else 0,
        'HighChol': 1 if HighChol else 0,
        'BMI': BMI,
        'Smoker': 1 if Smoker else 0,
        'Stroke': 1 if Stroke else 0,
        'HeartDiseaseorAttack': 1 if HeartDiseaseorAttack else 0,
        'PhysActivity': 1 if PhysActivity else 0,
        'NoDocbcCost': 1 if NoDocbcCost else 0,
        'GenHlth': GenHlth,
        'MentHlth': MentHlth,
        'PhysHlth': PhysHlth,
        'DiffWalk': 1 if DiffWalk else 0,
        'Sex': 1 if Sex == "Male" else 0,
        'Age': Age
    }

    feature_values = np.array([[features[col] for col in feature_columns]])
    TabNet_model = TabNetClassifier()
    try:
        TabNet_model.load_model("TabNet_model.zip")
    except Exception as e:
        return f"Failed to load TabNet model: {str(e)}"
    try:
        model_random_forest=joblib.load('random_forest_model.sav')
    except:
        return f"Failed to load Random Forest model: {str(e)}"
    try:
        feature_values_scaled = scaler.transform(feature_values)
        pred_NN = best_model.predict(feature_values_scaled)[0][0]
        pred_tabnet = TabNet_model.predict_proba(feature_values_scaled)[0][1]
        pred_random_forest = model_random_forest.predict_proba(feature_values_scaled)[0][1]
    except Exception as e:
        return f"ERROR in prediction: {str(e)}"

    #If predictions are arrays, flatten them
    if isinstance(pred_NN, np.ndarray):
        pred_NN = pred_NN.flatten()[0]
    if isinstance(pred_tabnet, np.ndarray):
        pred_tabnet = pred_tabnet.flatten()[0]
    if isinstance(pred_random_forest, np.ndarray):
        pred_random_forest = pred_random_forest.flatten()[0]
    # Format output nicely, assuming these predictions are probabilities or scores
    return f"Best Model Prediction: {pred_NN * 100:.2f}% | TabNet Prediction: {pred_tabnet * 100:.2f}% | RandomForest Prediction: {pred_random_forest * 100:.2f}%"

iface = gr.Interface(
    fn=submit_form,
    inputs=[
        gr.Checkbox(label="High Blood pressure"),
        gr.Checkbox(label="High Cholesterol"),
        gr.Slider(minimum=0, maximum=100, step=1, label="BMI (american Values)"),
        gr.Checkbox(label="Are you a Smoker?"),
        gr.Checkbox(label="Had Stroke?"),
        gr.Checkbox(label="Do you suffer from heart disorder?"),
        gr.Checkbox(label="Have you done physical activiy in the last 30 days?"),
        gr.Checkbox(label="Was there a time in the past 12 months when you needed to see a doctor but could not because of cost?"),
        gr.Slider(minimum=1, maximum=5, step=1, label="Genral Health"),
        gr.Slider(minimum=1, maximum=30, step=0, label="Days of poor mental health scale 1-30 days"),
        gr.Slider(minimum=1, maximum=30, step=0, label="Physical illness or injury days in past 30 days scale 1-30"),
        gr.Checkbox(label="Do you have serious difficulty walking or climbing stairs?"),
        gr.Radio(choices=["Male", "Female"], label="Sex"),
        gr.Slider(minimum=0, maximum=14, step=1, label="Age using the age scale of _AGEG5YR ")
    ],
    outputs="text",
    live=False,  # Changed to False to avoid too many predictions on input change
    allow_flagging="never"
)

iface.launch()

def create_model(input_dim, activation='relu', dropout_rate=0.4, learning_rate=0.001):
    model = Sequential()
    model.add(Dense(128, input_dim=input_dim, activation='relu', kernel_regularizer=l2(0.001)))
    model.add(BatchNormalization())
    model.add(Dropout(dropout_rate))

    model.add(Dense(64, activation=activation, kernel_regularizer=l2(0.001)))
    model.add(Dropout(dropout_rate))

    model.add(Dense(64, activation=activation, kernel_regularizer=l2(0.001)))
    model.add(Dropout(dropout_rate))

    model.add(Dense(32, activation=activation, kernel_regularizer=l2(0.001)))
    model.add(Dropout(dropout_rate))

    model.add(Dense(1, activation='sigmoid'))

    optimizer = Adam(learning_rate=learning_rate)

    model.compile(optimizer=optimizer,
                  loss='binary_crossentropy',
                  metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])
    return model

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import confusion_matrix
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
from tensorflow.keras.regularizers import l2
from tensorflow.keras.optimizers import Adam, RMSprop, SGD
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
import pickle
import os

feature_columns = [
    'HighBP', 'HighChol', 'BMI', 'Smoker', 'Stroke',
    'HeartDiseaseorAttack', 'PhysActivity',
    'NoDocbcCost', 'GenHlth',
    'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age'
]

scaler = MinMaxScaler()
df[feature_columns] = scaler.fit_transform(df[feature_columns])

X = df[feature_columns].values
y = df['Output'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)

print(f"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}")
print(f"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}")

# --- Hyperparameters & optimizer choices ---

optimizer_choices = {
    "adam": Adam,
    "rmsprop": RMSprop,
    "sgd": SGD,
}

epochs_list = [4, 8]
batch_sizes = [8, 16]
dropout_rates = [0.2, 0.4, 0.6]
activation_functions = ['relu', 'tanh', 'sigmoid']
learning_rates = [0.001, 0.0005]
optimizer_names = ['adam', 'rmsprop', 'sgd']

history_file = "training_history.pkl"

# Try loading existing history to append
if os.path.exists(history_file):
    with open(history_file, "rb") as f:
        all_history_data = pickle.load(f)
else:
    all_history_data = {
        "histories": [],
        "confusion_matrices": [],
        "params": [],
        "val_aucs": [],
        "models": [],  # model architecture JSON
        "weights": [], # model weights for later reloading
    }

input_dim = X_train.shape[1]

early_stopping = EarlyStopping(monitor='val_auc', mode='max', patience=10, restore_best_weights=True)
lr_scheduler = ReduceLROnPlateau(monitor='val_auc', mode='max', factor=0.5, patience=5, min_lr=0.0001, verbose=1)
# --- Training loop ---
for lr in learning_rates:
    for act_func in activation_functions:
        for dropout_rate in dropout_rates:
            for epochs in epochs_list:
                for batch_size in batch_sizes:
                    for optimizer_name in optimizer_names:
                        print(f"\nTraining model with lr={lr}, activation={act_func}, dropout={dropout_rate}, "
                              f"epochs={epochs}, batch_size={batch_size}, optimizer={optimizer_name}")

                        model = create_model(input_dim, activation=act_func, dropout_rate=dropout_rate,
                                             learning_rate=lr, optimizer_name=optimizer_name)

                        history = model.fit(
                            X_train, y_train,
                            epochs=epochs,
                            batch_size=batch_size,
                            validation_split=0.2,
                            callbacks=[early_stopping, lr_scheduler],
                            verbose=2
                        )

                        test_results = model.evaluate(X_test, y_test, verbose=0)
                        test_loss, test_accuracy, test_auc = test_results
                        print(f"Test accuracy: {test_accuracy*100:.2f}%, Test AUC: {test_auc:.4f}")

                        preds = model.predict(X_test)
                        preds_binary = (preds > 0.5).astype(int)
                        cm = confusion_matrix(y_test, preds_binary)

                        current_params = {
                            "learning_rate": lr,
                            "activation": act_func,
                            "dropout_rate": dropout_rate,
                            "epochs": epochs,
                            "batch_size": batch_size,
                            "optimizer": optimizer_name
                        }

                        history_record = {
                            "history": history.history,
                            "confusion_matrix": cm,
                            "params": current_params,
                            "test_auc": test_auc,
                            "test_accuracy": test_accuracy
                        }

                        all_history_data["histories"].append(history_record)
                        all_history_data["confusion_matrices"].append(cm)
                        all_history_data["params"].append(current_params)
                        all_history_data["val_aucs"].append(test_auc)
                        all_history_data["models"].append(model.to_json())
                        all_history_data["weights"].append(model.get_weights())

                        # Save after every run!
                        with open(history_file, "wb") as f:
                            pickle.dump(all_history_data, f)
                        print("Training history saved.\n")